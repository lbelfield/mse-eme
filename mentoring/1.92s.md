<h1>Why 1.92 Seconds</h1>

For: 
- Video of 25 fps, 1 video frame is 1/25
- Audio of 48kHz, 1 audio frame = 1024/48000

LCM (Least Common Multiple) of 1/25 and 1024/48000 is 0.32s so the fragment length needs to be a multiple of 0.32s.

0.32s = 8 video frames and 15 audio frames
0.32*6 = 1.92s = 48 video frames and 90 audio frames in each GOP

1 fragment = 1 GOP

</br><h3>Why Not Another Multiplier of 0.32s?</h3>

1. Reduce VST ( due to faster recovery of fragments ) 
2. Reduce time to play on skip or pause ( due to faster recovery of fragments ) 
3. reduced CIRR due to more efficient heuristics for ABR with smaller fragments ( needs work combined with timeout logic in player )
4. reduced latency ( broadcast delay ) due to efficencies in processing with encoding , packaging and delivery phase
5. combined with player cache optimisation for 3 fragments reduce latency due to reduced fragments to start playback

</br><h3>Example: Using stream.mpd</h3>

d/timescale=1.92
Our Timescale in this manifest is 12800 (in `<SegmentTemplate>`) and d is found in our `<S>`.

`<SegmentTemplate timescale="12800" initialization="video_2300000/init.mp4" media="video_2300000/$Number$.mp4" startNumber="1">`
    
`<SegmentTimeline>`

// t=start ,d=durationOfSegment , r=endofArray(repeat) So we have 156xfullmp4s and 1xhalfmp4 
d/timescale = 1.92 (24576/12800 = 1.92)

`<S t="0" d="24576" r="155"/> `

// 156 x 24576 = 3833856 (r x d = t), so our 156th segment starts at t=3833856.
Second Segment is 0.56s duration long (7168/12800 = 0.56)

`<S t="3833856" d="7168"/>`

`</SegmentTimeline>`